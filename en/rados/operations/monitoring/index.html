
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Monitoring a Cluster &mdash; Ceph Documentation</title>
    
    <link rel="stylesheet" href="../../../../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../../../',
        VERSION:     'dev',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../../_static/doctools.js"></script>
    <link rel="shortcut icon" href="../../../../_static/favicon.ico"/>
    <link rel="top" title="Ceph Documentation" href="../../../../" />
    <script type="text/javascript" src="http://ayni.ceph.com/public/js/ceph.js"></script>

  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../../genindex/" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../../../../py-modindex/" title="Python Module Index"
             >modules</a> |</li>
        <li><a href="../../../../">Ceph Documentation</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="monitoring-a-cluster">
<h1>Monitoring a Cluster<a class="headerlink" href="#monitoring-a-cluster" title="Permalink to this headline">¶</a></h1>
<p>Once you have a running cluster, you may use the <tt class="docutils literal"><span class="pre">ceph</span></tt> tool to monitor your
cluster. Monitoring a cluster typically involves checking OSD status, monitor
status, placement group status and metadata server status.</p>
<div class="section" id="interactive-mode">
<h2>Interactive Mode<a class="headerlink" href="#interactive-mode" title="Permalink to this headline">¶</a></h2>
<p>To run the <tt class="docutils literal"><span class="pre">ceph</span></tt> tool in interactive mode, type <tt class="docutils literal"><span class="pre">ceph</span></tt> at the command line
with no arguments.  For example:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">ceph</span>
<span class="n">ceph</span><span class="o">&gt;</span> <span class="n">health</span>
<span class="n">ceph</span><span class="o">&gt;</span> <span class="n">status</span>
<span class="n">ceph</span><span class="o">&gt;</span> <span class="n">quorum_status</span>
<span class="n">ceph</span><span class="o">&gt;</span> <span class="n">mon_status</span>
</pre></div>
</div>
</div>
<div class="section" id="checking-cluster-health">
<h2>Checking Cluster Health<a class="headerlink" href="#checking-cluster-health" title="Permalink to this headline">¶</a></h2>
<p>After you start your cluster, and before you start reading and/or
writing data, check your cluster&#8217;s health first. You can check on the
health of your Ceph cluster with the following:</p>
<div class="highlight-python"><pre>ceph health</pre>
</div>
<p>If you specified non-default locations for your configuration or keyring,
you may specify their locations:</p>
<div class="highlight-python"><pre>ceph -c /path/to/conf -k /path/to/keyring health</pre>
</div>
<p>Upon starting the Ceph cluster, you will likely encounter a health
warning such as <tt class="docutils literal"><span class="pre">HEALTH_WARN</span> <span class="pre">XXX</span> <span class="pre">num</span> <span class="pre">placement</span> <span class="pre">groups</span> <span class="pre">stale</span></tt>. Wait a few moments and check
it again. When your cluster is ready, <tt class="docutils literal"><span class="pre">ceph</span> <span class="pre">health</span></tt> should return a message
such as <tt class="docutils literal"><span class="pre">HEALTH_OK</span></tt>. At that point, it is okay to begin using the cluster.</p>
</div>
<div class="section" id="watching-a-cluster">
<h2>Watching a Cluster<a class="headerlink" href="#watching-a-cluster" title="Permalink to this headline">¶</a></h2>
<p>To watch the cluster&#8217;s ongoing events, open a new terminal. Then, enter:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">ceph</span> <span class="o">-</span><span class="n">w</span>
</pre></div>
</div>
<p>Ceph will print each event.  For example, a tiny Ceph cluster consisting of
one monitor, and two OSDs may print the following:</p>
<div class="highlight-python"><pre>cluster b370a29d-9287-4ca3-ab57-3d824f65e339
 health HEALTH_OK
 monmap e1: 1 mons at {ceph1=10.0.0.8:6789/0}, election epoch 2, quorum 0 ceph1
 osdmap e63: 2 osds: 2 up, 2 in
  pgmap v41338: 952 pgs, 20 pools, 17130 MB data, 2199 objects
        115 GB used, 167 GB / 297 GB avail
             952 active+clean

2014-06-02 15:45:21.655871 osd.0 [INF] 17.71 deep-scrub ok
2014-06-02 15:45:47.880608 osd.1 [INF] 1.0 scrub ok
2014-06-02 15:45:48.865375 osd.1 [INF] 1.3 scrub ok
2014-06-02 15:45:50.866479 osd.1 [INF] 1.4 scrub ok
2014-06-02 15:45:01.345821 mon.0 [INF] pgmap v41339: 952 pgs: 952 active+clean; 17130 MB data, 115 GB used, 167 GB / 297 GB avail
2014-06-02 15:45:05.718640 mon.0 [INF] pgmap v41340: 952 pgs: 1 active+clean+scrubbing+deep, 951 active+clean; 17130 MB data, 115 GB used, 167 GB / 297 GB avail
2014-06-02 15:45:53.997726 osd.1 [INF] 1.5 scrub ok
2014-06-02 15:45:06.734270 mon.0 [INF] pgmap v41341: 952 pgs: 1 active+clean+scrubbing+deep, 951 active+clean; 17130 MB data, 115 GB used, 167 GB / 297 GB avail
2014-06-02 15:45:15.722456 mon.0 [INF] pgmap v41342: 952 pgs: 952 active+clean; 17130 MB data, 115 GB used, 167 GB / 297 GB avail
2014-06-02 15:46:06.836430 osd.0 [INF] 17.75 deep-scrub ok
2014-06-02 15:45:55.720929 mon.0 [INF] pgmap v41343: 952 pgs: 1 active+clean+scrubbing+deep, 951 active+clean; 17130 MB data, 115 GB used, 167 GB / 297 GB avail</pre>
</div>
<p>The output provides:</p>
<ul class="simple">
<li>Cluster ID</li>
<li>Cluster health status</li>
<li>The monitor map epoch and the status of the monitor quorum</li>
<li>The OSD map epoch and the status of OSDs</li>
<li>The placement group map version</li>
<li>The number of placement groups and pools</li>
<li>The <em>notional</em> amount of data stored and the number of objects stored; and,</li>
<li>The total amount of data stored.</li>
</ul>
<div class="topic">
<p class="topic-title first">How Ceph Calculates Data Usage</p>
<p>The <tt class="docutils literal"><span class="pre">used</span></tt> value reflects the <em>actual</em> amount of raw storage used. The
<tt class="docutils literal"><span class="pre">xxx</span> <span class="pre">GB</span> <span class="pre">/</span> <span class="pre">xxx</span> <span class="pre">GB</span></tt> value means the amount available (the lesser number)
of the overall storage capacity of the cluster. The notional number reflects
the size of the stored data before it is replicated, cloned or snapshotted.
Therefore, the amount of data actually stored typically exceeds the notional
amount stored, because Ceph creates replicas of the data and may also use
storage capacity for cloning and snapshotting.</p>
</div>
</div>
<div class="section" id="checking-a-cluster-s-usage-stats">
<h2>Checking a Cluster&#8217;s Usage Stats<a class="headerlink" href="#checking-a-cluster-s-usage-stats" title="Permalink to this headline">¶</a></h2>
<p>To check a cluster&#8217;s data usage and data distribution among pools, you can
use the <tt class="docutils literal"><span class="pre">df</span></tt> option. It is similar to Linux <tt class="docutils literal"><span class="pre">df</span></tt>. Execute
the following:</p>
<div class="highlight-python"><pre>ceph df</pre>
</div>
<p>The <strong>GLOBAL</strong> section of the output provides an overview of the amount of
storage your cluster uses for your data.</p>
<ul class="simple">
<li><strong>SIZE:</strong> The overall storage capacity of the cluster.</li>
<li><strong>AVAIL:</strong> The amount of free space available in the cluster.</li>
<li><strong>RAW USED:</strong> The amount of raw storage used.</li>
<li><strong>% RAW USED:</strong> The percentage of raw storage used. Use this number in
conjunction with the <tt class="docutils literal"><span class="pre">full</span> <span class="pre">ratio</span></tt> and <tt class="docutils literal"><span class="pre">near</span> <span class="pre">full</span> <span class="pre">ratio</span></tt> to ensure that
you are not reaching your cluster&#8217;s capacity. See <a class="reference external" href="../../configuration/mon-config-ref#storage-capacity">Storage Capacity</a> for
additional details.</li>
</ul>
<p>The <strong>POOLS</strong> section of the output provides a list of pools and the notional
usage of each pool. The output from this section <strong>DOES NOT</strong> reflect replicas,
clones or snapshots. For example, if you store an object with 1MB of data, the
notional usage will be 1MB, but the actual usage may be 2MB or more depending
on the number of replicas, clones and snapshots.</p>
<ul class="simple">
<li><strong>NAME:</strong> The name of the pool.</li>
<li><strong>ID:</strong> The pool ID.</li>
<li><strong>USED:</strong> The notional amount of data stored in kilobytes, unless the number
appends <strong>M</strong> for megabytes or <strong>G</strong> for gigabytes.</li>
<li><strong>%USED:</strong> The notional percentage of storage used per pool.</li>
<li><strong>Objects:</strong> The notional number of objects stored per pool.</li>
</ul>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The numbers in the <strong>POOLS</strong> section are notional. They are not
inclusive of the number of replicas, shapshots or clones. As a result,
the sum of the <strong>USED</strong> and <strong>%USED</strong> amounts will not add up to the
<strong>RAW USED</strong> and <strong>%RAW USED</strong> amounts in the <strong>GLOBAL</strong> section of the
output.</p>
</div>
</div>
<div class="section" id="checking-a-cluster-s-status">
<h2>Checking a Cluster&#8217;s Status<a class="headerlink" href="#checking-a-cluster-s-status" title="Permalink to this headline">¶</a></h2>
<p>To check a cluster&#8217;s status, execute the following:</p>
<div class="highlight-python"><pre>ceph status</pre>
</div>
<p>Or:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">ceph</span> <span class="o">-</span><span class="n">s</span>
</pre></div>
</div>
<p>In interactive mode, type <tt class="docutils literal"><span class="pre">status</span></tt> and press <strong>Enter</strong>.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">ceph</span><span class="o">&gt;</span> <span class="n">status</span>
</pre></div>
</div>
<p>Ceph will print the cluster status. For example, a tiny Ceph  cluster consisting
of one monitor, and two OSDs may print the following:</p>
<div class="highlight-python"><pre>cluster b370a29d-9287-4ca3-ab57-3d824f65e339
 health HEALTH_OK
 monmap e1: 1 mons at {ceph1=10.0.0.8:6789/0}, election epoch 2, quorum 0 ceph1
 osdmap e63: 2 osds: 2 up, 2 in
  pgmap v41332: 952 pgs, 20 pools, 17130 MB data, 2199 objects
        115 GB used, 167 GB / 297 GB avail
               1 active+clean+scrubbing+deep
             951 active+clean</pre>
</div>
</div>
<div class="section" id="checking-osd-status">
<h2>Checking OSD Status<a class="headerlink" href="#checking-osd-status" title="Permalink to this headline">¶</a></h2>
<p>You can check OSDs to ensure they are <tt class="docutils literal"><span class="pre">up</span></tt> and <tt class="docutils literal"><span class="pre">in</span></tt> by executing:</p>
<div class="highlight-python"><pre>ceph osd stat</pre>
</div>
<p>Or:</p>
<div class="highlight-python"><pre>ceph osd dump</pre>
</div>
<p>You can also check view OSDs according to their position in the CRUSH map.</p>
<div class="highlight-python"><pre>ceph osd tree</pre>
</div>
<p>Ceph will print out a CRUSH tree with a host, its OSDs, whether they are up
and their weight.</p>
<div class="highlight-python"><pre># id    weight  type name       up/down reweight
-1      3       pool default
-3      3               rack mainrack
-2      3                       host osd-host
0       1                               osd.0   up      1
1       1                               osd.1   up      1
2       1                               osd.2   up      1</pre>
</div>
<p>For a detailed discussion, refer to <a class="reference external" href="../monitoring-osd-pg">Monitoring OSDs and Placement Groups</a>.</p>
</div>
<div class="section" id="checking-monitor-status">
<h2>Checking Monitor Status<a class="headerlink" href="#checking-monitor-status" title="Permalink to this headline">¶</a></h2>
<p>If your cluster has multiple monitors (likely), you should check the monitor
quorum status after you start the cluster before reading and/or writing data. A
quorum must be present when multiple monitors are running. You should also check
monitor status periodically to ensure that they are running.</p>
<p>To see display the monitor map, execute the following:</p>
<div class="highlight-python"><pre>ceph mon stat</pre>
</div>
<p>Or:</p>
<div class="highlight-python"><pre>ceph mon dump</pre>
</div>
<p>To check the quorum status for the monitor cluster, execute the following:</p>
<div class="highlight-python"><pre>ceph quorum_status</pre>
</div>
<p>Ceph will return the quorum status. For example, a Ceph  cluster consisting of
three monitors may return the following:</p>
<div class="highlight-javascript"><div class="highlight"><pre><span class="p">{</span> <span class="s2">&quot;election_epoch&quot;</span><span class="o">:</span> <span class="mi">10</span><span class="p">,</span>
  <span class="s2">&quot;quorum&quot;</span><span class="o">:</span> <span class="p">[</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">2</span><span class="p">],</span>
  <span class="s2">&quot;monmap&quot;</span><span class="o">:</span> <span class="p">{</span> <span class="s2">&quot;epoch&quot;</span><span class="o">:</span> <span class="mi">1</span><span class="p">,</span>
      <span class="s2">&quot;fsid&quot;</span><span class="o">:</span> <span class="s2">&quot;444b489c-4f16-4b75-83f0-cb8097468898&quot;</span><span class="p">,</span>
      <span class="s2">&quot;modified&quot;</span><span class="o">:</span> <span class="s2">&quot;2011-12-12 13:28:27.505520&quot;</span><span class="p">,</span>
      <span class="s2">&quot;created&quot;</span><span class="o">:</span> <span class="s2">&quot;2011-12-12 13:28:27.505520&quot;</span><span class="p">,</span>
      <span class="s2">&quot;mons&quot;</span><span class="o">:</span> <span class="p">[</span>
            <span class="p">{</span> <span class="s2">&quot;rank&quot;</span><span class="o">:</span> <span class="mi">0</span><span class="p">,</span>
              <span class="s2">&quot;name&quot;</span><span class="o">:</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span>
              <span class="s2">&quot;addr&quot;</span><span class="o">:</span> <span class="s2">&quot;127.0.0.1:6789\/0&quot;</span><span class="p">},</span>
            <span class="p">{</span> <span class="s2">&quot;rank&quot;</span><span class="o">:</span> <span class="mi">1</span><span class="p">,</span>
              <span class="s2">&quot;name&quot;</span><span class="o">:</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span>
              <span class="s2">&quot;addr&quot;</span><span class="o">:</span> <span class="s2">&quot;127.0.0.1:6790\/0&quot;</span><span class="p">},</span>
            <span class="p">{</span> <span class="s2">&quot;rank&quot;</span><span class="o">:</span> <span class="mi">2</span><span class="p">,</span>
              <span class="s2">&quot;name&quot;</span><span class="o">:</span> <span class="s2">&quot;c&quot;</span><span class="p">,</span>
              <span class="s2">&quot;addr&quot;</span><span class="o">:</span> <span class="s2">&quot;127.0.0.1:6791\/0&quot;</span><span class="p">}</span>
           <span class="p">]</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="checking-mds-status">
<h2>Checking MDS Status<a class="headerlink" href="#checking-mds-status" title="Permalink to this headline">¶</a></h2>
<p>Metadata servers provide metadata services for  Ceph FS. Metadata servers have
two sets of states: <tt class="docutils literal"><span class="pre">up</span> <span class="pre">|</span> <span class="pre">down</span></tt> and <tt class="docutils literal"><span class="pre">active</span> <span class="pre">|</span> <span class="pre">inactive</span></tt>. To ensure your
metadata servers are <tt class="docutils literal"><span class="pre">up</span></tt> and <tt class="docutils literal"><span class="pre">active</span></tt>,  execute the following:</p>
<div class="highlight-python"><pre>ceph mds stat</pre>
</div>
<p>To display details of the metadata cluster, execute the following:</p>
<div class="highlight-python"><pre>ceph mds dump</pre>
</div>
</div>
<div class="section" id="checking-placement-group-states">
<h2>Checking Placement Group States<a class="headerlink" href="#checking-placement-group-states" title="Permalink to this headline">¶</a></h2>
<p>Placement groups map objects to OSDs. When you monitor your
placement groups,  you will want them to be <tt class="docutils literal"><span class="pre">active</span></tt> and <tt class="docutils literal"><span class="pre">clean</span></tt>.
For a detailed discussion, refer to <a class="reference external" href="../monitoring-osd-pg">Monitoring OSDs and Placement Groups</a>.</p>
</div>
<div class="section" id="using-the-admin-socket">
<h2>Using the Admin Socket<a class="headerlink" href="#using-the-admin-socket" title="Permalink to this headline">¶</a></h2>
<p>The Ceph admin socket allows you to query a daemon via a socket interface.
By default, Ceph sockets reside under <tt class="docutils literal"><span class="pre">/var/run/ceph</span></tt>. To access a daemon
via the admin socket, login to the host running the daemon and use the
following command:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">ceph</span> <span class="o">--</span><span class="n">admin</span><span class="o">-</span><span class="n">daemon</span> <span class="o">/</span><span class="n">var</span><span class="o">/</span><span class="n">run</span><span class="o">/</span><span class="n">ceph</span><span class="o">/</span><span class="p">{</span><span class="n">socket</span><span class="o">-</span><span class="n">name</span><span class="p">}</span>
</pre></div>
</div>
<p>To view the available admin socket commands, execute the following command:</p>
<div class="highlight-python"><pre>ceph --admin-daemon /var/run/ceph/{socket-name} help</pre>
</div>
<p>The admin socket command enables you to show and set your configuration at
runtime. See <a class="reference external" href="../../configuration/ceph-conf#ceph-runtime-config">Viewing a Configuration at Runtime</a> for details.</p>
<p>Additionally, you can set configuration values at runtime directly (i.e., the
admin socket bypasses the monitor, unlike <tt class="docutils literal"><span class="pre">ceph</span> <span class="pre">tell</span> <span class="pre">{daemon-type}.{id}</span>
<span class="pre">injectargs</span></tt>, which relies on the monitor but doesn&#8217;t require you to login
directly to the host in question ).</p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../../../../">
              <img class="logo" src="../../../../_static/logo.png" alt="Logo"/>
            </a></p>
<h3><a href="../../../../">Table Of Contents</a></h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../start/intro/">Ceph 简介</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../start/">安装（快速）</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../install/">安装（手动）</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../rados/">Ceph 存储集群</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../cephfs/">Ceph 文件系统</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../rbd/rbd/">Ceph 块设备</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../radosgw/">Ceph 对象网关</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api/">API 文档</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../architecture/">体系结构</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../dev/">开发文档</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../release-notes/">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../releases/">发布时间表</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../glossary/">Ceph 术语</a></li>
</ul>


<!-- ugly kludge to make genindex look like it's part of the toc -->
<ul style="margin-top: -10px"><li class="toctree-l1"><a class="reference internal" href="../../../../genindex/">Index</a></li></ul>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="../../../../search/" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../../genindex/" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../../../../py-modindex/" title="Python Module Index"
             >modules</a> |</li>
        <li><a href="../../../../">Ceph Documentation</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2010-2014, Inktank Storage, Inc. and contributors. Licensed under Creative Commons BY-SA.
    </div>
  </body>
</html>